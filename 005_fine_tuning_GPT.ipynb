{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae71646-4204-45e3-97a6-e89d098207ae",
   "metadata": {},
   "source": [
    "# FINE TUNING\n",
    "\n",
    "Obiettivo di questo notebook è verificare come effettuare fine tuning del GPT pre-trained con i weights di OPENAI con 2 diversi obiettivi:\n",
    "- classification fine tuning : serve per categorizzare i dati in input tra diverse classi pre-definite\n",
    "- instruction fine tuning : serve per far si che il modello sia in grado di capire e generare risposte a fronte di istruzioni impartite per mezzo di un prompt\n",
    "\n",
    "Il secondo caso richiede molte più risorse rispetto al primo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a35318d-0e97-4f5d-b310-5c35e1ce7bb8",
   "metadata": {},
   "source": [
    "## Classification fine tuning\n",
    "\n",
    "Primo step è sempre quello di preparare un dataset. <br>\n",
    "Nel nostro caso utilizziamo un dataset di messaggi di testo che dovranno essere classificati in spam o non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4b06984b-6eab-4516-a573-b61472d6e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "\n",
    "\n",
    "def download_and_unzip_spam_data(\n",
    "        url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download \"\n",
    "              \"and extraction.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # Downloads the file\n",
    "    with urllib.request.urlopen(url) as response:   \n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzips the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:    \n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "\n",
    "    # Adds a .tsv file extension \n",
    "    os.rename(original_file_path, data_file_path)               \n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11054f3c-c94a-4728-88b9-5eea14f55d5a",
   "metadata": {},
   "source": [
    "Importo il dataset in un pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68a6dafd-f995-4a12-8f74-ce1a8bb1e166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"]\n",
    ")\n",
    "df    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef0dd99-31df-4e35-9568-c255385c6690",
   "metadata": {},
   "source": [
    "E' possibile verificare che la distribuzione delle classi è sbilanciata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bbe675b3-1104-4d28-9d0d-d1afacefbbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4226ae-b097-48cc-a73c-d2460249cdd1",
   "metadata": {},
   "source": [
    "Per bilanciare il dataset effettuo undersample della classe più numerosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b1df8cff-a20a-4dab-8fde-ffbf209c0c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "\n",
    "    # Counts the instances of “spam” \n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]    \n",
    "    \n",
    "    # Randomly samples “ham” instances to match the number of “spam” instances \n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(\n",
    "        num_spam, random_state=123\n",
    "    )                                         \n",
    "    \n",
    "    #  Combines ham subset with “spam” \n",
    "    balanced_df = pd.concat([\n",
    "        ham_subset, df[df[\"Label\"] == \"spam\"]\n",
    "    ])                               #3\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb0add9-4384-4aa7-9146-20f71e8ed7ab",
   "metadata": {},
   "source": [
    "Infine convertiamo le 2 labels da formato testo a integer class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9156fc25-6364-4620-8c40-f101065fbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f87262ac-ca57-42aa-9d0d-a653023cb5d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f8eac-3837-49dc-afbb-14ac1e70f84e",
   "metadata": {},
   "source": [
    "Infine splittiamo il dataset in train, validation e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d5cc869-a89f-4162-8fa7-1d089f49e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "\n",
    "    # Shuffles the entire DataFrame \n",
    "    df = df.sample(\n",
    "        frac=1, random_state=123\n",
    "    ).reset_index(drop=True)              \n",
    "    \n",
    "    #  Calculates split indices \n",
    "    train_end = int(len(df) * train_frac)         \n",
    "    \n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Splits the DataFrame \n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a44d8-215a-41b1-925d-c20338c46c14",
   "metadata": {},
   "source": [
    "Infine esportiamo i 3 dataframe ottenuti in formato csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5553427b-ed6b-4eee-8c95-74b44bddf52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3891d8b-7246-491c-86e8-8a563c7212ba",
   "metadata": {},
   "source": [
    "## Dataloaders\n",
    "\n",
    "Dal momento che i messaggi sono di diversa lunghezza ho 2 possibilità:\n",
    "- troncare i messaggi alla dimensione del più corto del dataset o del batch\n",
    "- effettuare il padding alla lunghezza del più lungo\n",
    "\n",
    "Optiamo x la seconda possibilità aggiungendo padding token ai messaggi più corti. Aggiungiamo quindi direttamente il tokenid corrispondete a \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9c16fb59-c0a2-42e6-9de1-3e0dfe41f7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2abfaa-19ca-47f5-9e80-ae33bf5ce62e",
   "metadata": {},
   "source": [
    "Prima di creare il dataloader è necessario creare il Pytorch Dataset che specifica come i dati sono caricati e processati.<br>\n",
    "La classe SpamDataset:\n",
    "- identifica il messaggio più lungo\n",
    "- fa encode dei messaggi di testo\n",
    "- effettua padding dei messaggi più corti aggiungendo i token <|endoftext|> \n",
    "\n",
    "In modo che tutti gli input tensor siano della stessa lunghezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e8055766-0121-4220-9f77-12b421b68494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "\n",
    "    # Pretokenizes texts \n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "        \n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        # Truncates sequences if they are longer than max_length\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length]\n",
    "                for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "\n",
    "        # Pads sequences to the longest sequence \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * \n",
    "            (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length\n",
    "        return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ea8b172f-cbcd-4f96-8471-0b38bbd4a389",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fea0fb20-dfb2-469b-8a0f-7a7a59c6af12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fcd009-3a94-45a1-ad2c-2618edd7a401",
   "metadata": {},
   "source": [
    "Dal momento che il modello supporta context size di 1024 tokens, non c'è problema. Se ci fossero messaggi più lunghi sarebbe necessario settare max_lenght=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "214c25d8-48c1-4cc3-ae82-29f95d50c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a47c86a-9104-4797-89da-b5197302d971",
   "metadata": {},
   "source": [
    "E' ora possibile creare i dataloader utilizzando Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2e2edc0-031c-404f-83ab-2a5127fab85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# This setting ensures compatibility with most computers. \n",
    "num_workers = 0     \n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5746f026-885e-4eb6-95fd-273be0a6aa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aabff0a7-aa9a-481b-8ac8-7f039434d562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7142a725-6db2-4d57-9c97-556ded71b79c",
   "metadata": {},
   "source": [
    "Prima di iniziare il classification fine tuning è necessario inizializzare il modello con i pretrained weights di OpenAI \n",
    "come fatto nel precedente notebook con unlabelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dac29a19-ec73-4040-ba1a-4d2053c59aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,          #1\n",
    "    \"context_length\": 1024,       #2\n",
    "    \"drop_rate\": 0.0,             #3\n",
    "    \"qkv_bias\": True              #4\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81781105-1857-4973-9f1b-6a1cba01bc1f",
   "metadata": {},
   "source": [
    "Copio dal notebook precedente tutti i moduli che compongono GPTModel e la funzione load_weights_into_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "94b5cf71-5e6a-4318-8a79-83bce34df289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift\n",
    "        \n",
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))\n",
    "        \n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
    "            GELU(),\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert d_out % num_heads == 0, \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "\n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
    "\n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec)  # optional projection\n",
    "\n",
    "        return context_vec\n",
    " \n",
    "class TransformerBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Shortcut connection for attention block \n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        # Add the original input back \n",
    "        x = x + shortcut      \n",
    "\n",
    "        # Shortcut connection for feed forward block \n",
    "        shortcut = x         \n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = self.drop_shortcut(x)\n",
    "\n",
    "        \n",
    "        x = x + shortcut      \n",
    "        return x\n",
    "\n",
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "\n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        \n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "\n",
    "        # The device setting will allow us to train the model on a CPU or GPU, depending on which device the input data sits on\n",
    "        pos_embeds = self.pos_emb(\n",
    "            torch.arange(seq_len, device=in_idx.device)\n",
    "        )\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, \"\n",
    "                          \"Right: {right.shape}\"\n",
    "        )\n",
    "    return torch.nn.Parameter(torch.tensor(right))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sets the model’s positional and token embedding weights to those specified in params. \n",
    "def load_weights_into_gpt(gpt, params):          \n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    # Iterates over each transformer block in the model \n",
    "    for b in range(len(params[\"blocks\"])):    \n",
    "\n",
    "        # The np.split function is used to divide the attention and bias weights \n",
    "        # into three equal parts for the query, key, and value components. \n",
    "        q_w, k_w, v_w = np.split(                           \n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "\n",
    "    # The original GPT-2 model by OpenAI reused the token embedding weights in the output layer\n",
    "    # to reduce the total number of parameters, which is a concept known as weight tying. \n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6b54123c-0e31-49a0-a0af-e8bc1634836d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 16:27:59.579765: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=model_size, models_dir=\"gpt2\"\n",
    ")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c0e756-bcfb-4926-8ef8-117f54bfbb73",
   "metadata": {},
   "source": [
    "Copio anche le funzioni dei notebook precedenti al fine di generare testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ce15f072-2153-4af1-90e4-305620aca49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)    #1\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)                #2\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "def generate_text_simple(model, \n",
    "                         idx,        # idx is a (batch, n_tokens) array of indices in the current context. \n",
    "                         max_new_tokens,\n",
    "                         context_size): \n",
    "    for _ in range(max_new_tokens):\n",
    "\n",
    "        # Crops current context if it exceeds the supported context size,\n",
    "        # e.g., if LLM supports only 5 tokens, and the context size is 10, then only the last 5 tokens are used as context \n",
    "        idx_cond = idx[:, -context_size:]   \n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "\n",
    "        # Focuses only on the last time step, so that (batch, n_token, vocab_size) becomes (batch, vocab_size) \n",
    "        logits = logits[:, -1, :]                    \n",
    "        # probas has shape (batch, vocab_size). \n",
    "        probas = torch.softmax(logits, dim=-1)          \n",
    "        # idx_next has shape (batch, 1). \n",
    "        idx_next = torch.argmax(probas, dim=-1, keepdim=True)   \n",
    "        # Appends sampled index to the running sequence, where idx has shape (batch, n_tokens+1) \n",
    "        idx = torch.cat((idx, idx_next), dim=1)    \n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab393e42-6c42-4519-a97a-59d0b16018fd",
   "metadata": {},
   "source": [
    "Infine verifico se il modello pretrained è in grado di produrre testo coerente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "21bab653-6897-43ef-8343-1f44af4a7c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "text_1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6553338-9e3f-4035-b8ce-ba4822238e0f",
   "metadata": {},
   "source": [
    "Dopo aver verificato che il modello è in grado di generare contenuti testuali coerenti, provo a verificare la sua capacità di classificare un testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c64aa0e0-b40c-45ab-9423-f28c01901059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb0576-1930-4fdf-bb1d-c0ffcdda3ee5",
   "metadata": {},
   "source": [
    "Ovviamente allo stato attuale non è ancora in grado di fare l'attività di classificazione.<br>\n",
    "Per far ciò è necessario procedere ad aggiungere un <b>CLASSIFICATION HEAD</B> al posto dell'attuale output layer.\n",
    "\n",
    "Il nuovo output layer dovrà mappare la rappresentazione dell'LLM (hidden layer di 768 units) sulle 2 possibili classi di output (SPAM/NO SPAM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99894a3-6a02-4401-a7b4-56de87698708",
   "metadata": {},
   "source": [
    "Come primo step procediamo a rendere non trainable i weights del modello pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8202f077-0095-4f71-81c7-a70bfd36b067",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a605c9-2c96-45ce-8b57-fe01d947fbff",
   "metadata": {},
   "source": [
    "e sostituiamo l'output layer originale con quello adatto per la classificazione binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4cbed02a-1b6e-4205-b76e-f1bc2a0134f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "    in_features=BASE_CONFIG[\"emb_dim\"], \n",
    "    out_features=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38435259-9fe8-43a1-a8d4-4970b822b71b",
   "metadata": {},
   "source": [
    "Tecnicamente questo layer è l'unico di cui dovrebbe essere fatto il training ma è stato rilevato che, per migliorare le prestazioni, è opportuno effettuare il training anche dei layer più esterni (ultimo transformer block + Layernorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2298f310-61ff-4e1a-95f7-f5352cfc027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692238c3-f310-4bac-a85a-8dc927913aa8",
   "metadata": {},
   "source": [
    "Il modello si aspetta sempre un input dello stesso formato precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25b9ac2b-7c3a-4afb-b7d0-0142291e794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "\n",
    "# converto la lista in tensor e aggiungo la dimensione del batch\n",
    "inputs = torch.tensor(inputs).unsqueeze(0) \n",
    "print(\"Inputs:\", inputs)\n",
    "\n",
    "# shape: (batch_size, num_tokens) \n",
    "print(\"Inputs dimensions:\", inputs.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7851a8db-5719-46aa-84dc-9bbec47dbe75",
   "metadata": {},
   "source": [
    "..e questo input può essere passato al modello come prima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc3e21f2-db5d-48fe-828d-5429ac05e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e963ac9-7893-4ddb-a35a-33d7542364e6",
   "metadata": {},
   "source": [
    "Dal momento che l'obiettivo del modello è classificare la sequenza di input in una delle 2 classi, è sufficiente effettuare il fine tuning solo sull'ultimo output token che, dal momento che viene utilizzata causal attention, è il token che raggruppa informazioni su tutti i token presenti in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bcae125e-04c6-4677-a95d-a337718e6a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd9a514-2728-4862-bb74-9b25d892a121",
   "metadata": {},
   "source": [
    "Per convertire questi token nella previsione SPAM o NO SPAM si utilizza lo stesso approccio utilizzato per il pre-training: si converte questi token nelle corrispondenti probabilità utilizzando la funzione softmax e si sceglie quello con probabilità più alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1f5b696a-986e-4710-b08a-a0c78b1cd83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678097e0-e7ce-40b5-a577-58f265812b2d",
   "metadata": {},
   "source": [
    "Prima di poter effettuare il fine tuning è però necessario implementare la funzione di valutazione del modello da utilizzare durante il fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7ac4276d-990d-489a-b0b9-f0fcd20f0be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch = input_batch.to(device)\n",
    "            target_batch = target_batch.to(device)\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # Logits of last output token \n",
    "                logits = model(input_batch)[:, -1, :]     \n",
    "            predicted_labels = torch.argmax(logits, dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (\n",
    "                (predicted_labels == target_batch).sum().item()\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4eaea8-36ff-4140-a223-7da63b67d420",
   "metadata": {},
   "source": [
    "Possiamo testa la funzione per calcolare l'accuracy prendendo 10 batch random per i 3 dataset.<br>\n",
    "Ovviamente, essendo in modello non ancora fine-tuned, i risultati sono random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e43da7ad-45fd-4384-a39b-4cd41289726e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "train_accuracy = calc_accuracy_loader(\n",
    "    train_loader, model, device, num_batches=10\n",
    ")\n",
    "val_accuracy = calc_accuracy_loader(\n",
    "    val_loader, model, device, num_batches=10\n",
    ")\n",
    "test_accuracy = calc_accuracy_loader(\n",
    "    test_loader, model, device, num_batches=10\n",
    ")\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86ecebd-ece2-4039-bdda-dd8c385979c8",
   "metadata": {},
   "source": [
    "Dal momento che accuracy non è differenziabile, dobbiamo calcolare cross-entropy come funzione sostitutiva per massimizzare l'accuracy. A differenza di cross-entropy calcolata per il pre-trainig però, in questo caso dobbiamo ottimizzare solo l'ultimo token.\n",
    "\n",
    "DEfinisco la funzione per calcolare loss per un singolo batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84f2651f-8888-4cb6-935f-fe23da82e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)[:, -1, :]     #1\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce007bd-a492-41bd-b204-2e970171b932",
   "metadata": {},
   "source": [
    "E per calcolare loss per tutti i batch restituiti dal dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c94bfbf3-c2bb-43b2-817f-37a7b6a5b038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "\n",
    "    # Ensures number of batches doesn’t exceed batches in data loader \n",
    "    else:                                        \n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a31ba-a175-4bda-8499-d9f43c364087",
   "metadata": {},
   "source": [
    "Calcoliamo loss iniziale per ciascun data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7743eff1-24a7-4770-8782-30d419228f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():                 #1\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77095e3-54f9-4540-ab71-1d459b0d03cf",
   "metadata": {},
   "source": [
    "E' ora possibile fare il training del modello al fine di minimizzare il training loss (e massimizzare accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1960341d-a3f2-4d4c-b5b7-8c40de33bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter):\n",
    "    \n",
    "    # Initialize lists to track losses and examples seen \n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []   \n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    #  Main training loop \n",
    "    for epoch in range(num_epochs):    \n",
    "        #  Sets model to training mode \n",
    "        model.train()            \n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            #  Resets loss gradients from the previous batch iteration \n",
    "            optimizer.zero_grad()                     \n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            # Calculates loss gradients \n",
    "            loss.backward()                          \n",
    "            # Updates model weights using loss gradients \n",
    "            optimizer.step()                          \n",
    "            # New: tracks examples instead of tokens \n",
    "            examples_seen += input_batch.shape[0]    \n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step \n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Calculates accuracy after each epoch \n",
    "        train_accuracy = calc_accuracy_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_accuracy = calc_accuracy_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f7bdb9-f933-4ed6-b4a8-fd6d340a4ca3",
   "metadata": {},
   "source": [
    "Evaluate model è identico al pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dbdd26dd-f5c1-492d-a4e1-7f7a0875e4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df15b57-ee3d-4c80-83e0-05ccc401b423",
   "metadata": {},
   "source": [
    "E' ora possibile fare il fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c19446e4-bc91-416a-bbdf-5f58da6345b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 1.977, Val loss 2.196\n",
      "Ep 1 (Step 000050): Train loss 0.615, Val loss 0.636\n",
      "Ep 1 (Step 000100): Train loss 0.520, Val loss 0.555\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.563, Val loss 0.488\n",
      "Ep 2 (Step 000200): Train loss 0.418, Val loss 0.395\n",
      "Ep 2 (Step 000250): Train loss 0.408, Val loss 0.352\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.330, Val loss 0.314\n",
      "Ep 3 (Step 000350): Train loss 0.278, Val loss 0.181\n",
      "Training accuracy: 90.00% | Validation accuracy: 92.50%\n",
      "Ep 4 (Step 000400): Train loss 0.076, Val loss 0.131\n",
      "Ep 4 (Step 000450): Train loss 0.125, Val loss 0.099\n",
      "Ep 4 (Step 000500): Train loss 0.202, Val loss 0.102\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Ep 5 (Step 000550): Train loss 0.206, Val loss 0.110\n",
      "Ep 5 (Step 000600): Train loss 0.067, Val loss 0.056\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 7.82 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "    train_classifier_simple(\n",
    "        model, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs=num_epochs, eval_freq=50,\n",
    "        eval_iter=5\n",
    "    )\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4e4585c5-e00b-49b3-bd51-1b82c4bf1fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(\n",
    "        epochs_seen, examples_seen, train_values, val_values,\n",
    "        label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    " #1\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_values, linestyle=\"-.\",\n",
    "        label=f\"Validation {label}\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    " #2\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)    #3\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()             #4\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2cb1e7f9-ab67-4d4e-85cb-52c277bc43fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(\n",
    "    epochs_tensor, examples_seen_tensor, train_accs, val_accs,\n",
    "    label=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8e3d5ff0-c7bc-427b-a9a1-a82f74514840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 97.60%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a886f8b-4d53-4ae6-a1e4-dd6b229c281f",
   "metadata": {},
   "source": [
    "Una volta concluso il fine-tuning è possibile procedere con la classificazione dei messaggi tra SPAM e NO SPAM utilizzando il modello fine-tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5d607d8f-8c94-4f72-ade3-b54bf107602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "        text, model, tokenizer, device, max_length=None,\n",
    "        pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepares inputs to the model \n",
    "    input_ids = tokenizer.encode(text)          \n",
    "    supported_context_length = model.pos_emb.weight.shape[1]\n",
    "\n",
    "    #  Truncates sequences if they are too long \n",
    "    input_ids = input_ids[:min(              \n",
    "        max_length, supported_context_length\n",
    "    )]\n",
    "\n",
    "    # Pads sequences to the longest sequence \n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))    \n",
    "\n",
    "    # Adds batch dimension \n",
    "    input_tensor = torch.tensor(\n",
    "        input_ids, device=device\n",
    "    ).unsqueeze(0)              \n",
    "\n",
    "    # Models inference without gradient tracking \n",
    "    with torch.no_grad():                                \n",
    "        logits = model(input_tensor)[:, -1, :]     # Logits of the last output token \n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Returns the classified result \n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\"     #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1cfa8d19-a2b6-48d0-a07b-9877d1a2ee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0fefba12-7e9e-4a0e-8824-aa26673a3640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621eb0f9-c3d5-4669-ac60-b722f5eb88c4",
   "metadata": {},
   "source": [
    "Una volta testato che il modello funziona correttamente è possibile procedere con il salvataggio del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "90db2dc3-4480-4f11-9e4c-35a7cd74b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453756b0-a364-4cf1-8e07-8613a6555463",
   "metadata": {},
   "source": [
    "Una volta salvato il modello può essere caricato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c5d147a0-a617-4d94-b4d3-7a4ba5d07dd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device)\n",
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b52f9cd-4ce8-4bda-9910-5ffb8b342633",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
